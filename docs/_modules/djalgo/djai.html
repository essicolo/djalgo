<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>djalgo.djai &#8212; Djalgo 0.1-alpha documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=12dfc556" />
    <script src="../../_static/documentation_options.js?v=737112c1"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for djalgo.djai</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">miditok</span> <span class="kn">import</span> <span class="n">REMI</span><span class="p">,</span> <span class="n">TokenizerConfig</span>
<span class="kn">from</span> <span class="nn">miditok.pytorch_data</span> <span class="kn">import</span> <span class="n">DatasetMIDI</span><span class="p">,</span> <span class="n">DataCollator</span>

<div class="viewcode-block" id="ModelManager">
<a class="viewcode-back" href="../../api.html#djalgo.djai.ModelManager">[docs]</a>
<span class="k">class</span> <span class="nc">ModelManager</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Manages the initialization, training, and generation of a neural network model for MIDI sequence generation.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        seq_len_input (int): Length of input sequences.</span>
<span class="sd">        seq_len_output (int): Length of output sequences.</span>
<span class="sd">        model_type (str): Type of model to use (&#39;lstm&#39;, &#39;gru&#39;, &#39;transformer&#39;).</span>
<span class="sd">        nn_units (tuple): Number of units in each layer of the neural network.</span>
<span class="sd">        dropout (float): Dropout rate for the neural network.</span>
<span class="sd">        batch_size (int): Number of samples per batch.</span>
<span class="sd">        learning_rate (float): Learning rate for the optimizer.</span>
<span class="sd">        n_heads (int, optional): Number of attention heads (used for transformer model).</span>
<span class="sd">        tokenizer (miditok.REMI): Tokenizer for MIDI files.</span>
<span class="sd">        input_size (int): Size of the input vocabulary.</span>
<span class="sd">        model (torch.nn.Module): Neural network model.</span>
<span class="sd">        optimizer (torch.optim.Optimizer): Optimizer for training the model.</span>
<span class="sd">        loss_fn (torch.nn.Module): Loss function for training the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_length_input</span><span class="p">,</span> <span class="n">sequence_length_output</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">nn_units</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the ModelManager with specified parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            sequence_length_input (int): Length of input sequences.</span>
<span class="sd">            sequence_length_output (int): Length of output sequences.</span>
<span class="sd">            model_type (str): Type of model to use (&#39;lstm&#39;, &#39;gru&#39;, &#39;transformer&#39;).</span>
<span class="sd">            nn_units (tuple): Number of units in each layer of the neural network.</span>
<span class="sd">            dropout (float): Dropout rate for the neural network.</span>
<span class="sd">            batch_size (int): Number of samples per batch.</span>
<span class="sd">            learning_rate (float): Learning rate for the optimizer.</span>
<span class="sd">            n_heads (int, optional): Number of attention heads (used for transformer model).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len_input</span> <span class="o">=</span> <span class="n">sequence_length_input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len_output</span> <span class="o">=</span> <span class="n">sequence_length_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">=</span> <span class="n">model_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nn_units</span> <span class="o">=</span> <span class="n">nn_units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>

        <span class="c1"># Initialize the MidiTok tokenizer with custom configuration</span>
        <span class="n">TOKENIZER_PARAMS</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;pitch_range&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="mi">109</span><span class="p">),</span>
            <span class="s2">&quot;beat_res&quot;</span><span class="p">:</span> <span class="p">{(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mi">8</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">):</span> <span class="mi">4</span><span class="p">},</span>
            <span class="s2">&quot;num_velocities&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s2">&quot;special_tokens&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;PAD&quot;</span><span class="p">,</span> <span class="s2">&quot;BOS&quot;</span><span class="p">,</span> <span class="s2">&quot;EOS&quot;</span><span class="p">,</span> <span class="s2">&quot;MASK&quot;</span><span class="p">],</span>
            <span class="s2">&quot;use_chords&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;use_rests&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;use_tempos&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;use_time_signatures&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s2">&quot;use_programs&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s2">&quot;num_tempos&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s2">&quot;tempo_range&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">250</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">TokenizerConfig</span><span class="p">(</span><span class="o">**</span><span class="n">TOKENIZER_PARAMS</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">REMI</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

        <span class="c1"># Create the model</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;transformer&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">TransformerModel</span><span class="p">(</span><span class="n">nn_units</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;lstm&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">LSTMModel</span><span class="p">(</span><span class="n">nn_units</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;gru&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">GRUModel</span><span class="p">(</span><span class="n">nn_units</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported model type. Choose &#39;lstm&#39;, &#39;gru&#39;, or &#39;transformer&#39;.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<div class="viewcode-block" id="ModelManager.fit">
<a class="viewcode-back" href="../../api.html#djalgo.djai.ModelManager.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">midi_files_path</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the model on the specified MIDI files for a given number of epochs.</span>

<span class="sd">        Args:</span>
<span class="sd">            midi_files_path (str): Path to the directory containing MIDI files.</span>
<span class="sd">            epochs (int): Number of epochs to train the model.</span>
<span class="sd">            verbose (int or None, optional): Number of steps between progress messages or None for no messages (default: None).</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.nn.Module: Trained model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset_chunks_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">midi_files_path</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">DatasetMIDI</span><span class="p">(</span>
            <span class="n">files_paths</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">dataset_chunks_dir</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;**/*.mid&quot;</span><span class="p">)),</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">max_seq_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len_input</span>
        <span class="p">)</span>
        <span class="n">collator</span> <span class="o">=</span> <span class="n">DataCollator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="n">copy_inputs_as_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collator</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">current_step</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">],</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>

                <span class="c1"># One-hot encode inputs</span>
                <span class="n">inputs_one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">inputs_one_hot</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">inputs_one_hot</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input contains NaN or Inf values.&quot;</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;transformer&#39;</span><span class="p">:</span>
                    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span>
                    <span class="n">attention_mask_bool</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs_one_hot</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask_bool</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs_one_hot</span><span class="p">)</span>  <span class="c1"># No attention mask for other types</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss contains NaN or Inf values.&quot;</span><span class="p">)</span>
                    <span class="k">continue</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">current_step</span> <span class="o">%</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Step </span><span class="si">{</span><span class="n">current_step</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">current_step</span> <span class="o">+=</span> <span class="mi">1</span>


        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span></div>


<div class="viewcode-block" id="ModelManager.generate">
<a class="viewcode-back" href="../../api.html#djalgo.djai.ModelManager.generate">[docs]</a>
    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">primer_file</span><span class="p">,</span> <span class="n">output_file</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates a MIDI sequence based on a primer file and saves it to an output file.</span>

<span class="sd">        Args:</span>
<span class="sd">            length (int): Length of the sequence to generate.</span>
<span class="sd">            primer_file (str): Path to the primer MIDI file.</span>
<span class="sd">            output_file (str): Path to save the generated MIDI file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Tokenize the primer file using the correct method</span>
        <span class="n">midi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">primer_file</span><span class="p">))</span>
        <span class="n">primer_tokens</span> <span class="o">=</span> <span class="n">midi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ids</span>  <span class="c1"># Assuming single-track MIDI</span>
        <span class="n">primer_one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">primer_tokens</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Simplified prediction method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">generated</span> <span class="o">=</span> <span class="n">primer_one_hot</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span>
            <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">next_one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">next_token</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">generated</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">generated</span><span class="p">,</span> <span class="n">next_one_hot</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Convert generated tokens back to MIDI</span>
        <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">generated</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">generated_midi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">generated_tokens</span><span class="p">])</span>
        <span class="n">generated_midi</span><span class="o">.</span><span class="n">dump_midi</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">output_file</span><span class="p">))</span></div>


<div class="viewcode-block" id="ModelManager.save">
<a class="viewcode-back" href="../../api.html#djalgo.djai.ModelManager.save">[docs]</a>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves the model state to a file.</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): Path to save the model state.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">file_path</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="LSTMModel">
<a class="viewcode-back" href="../../api.html#djalgo.djai.LSTMModel">[docs]</a>
<span class="k">class</span> <span class="nc">LSTMModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines an LSTM model for sequence generation.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        layers (torch.nn.ModuleList): List of LSTM layers.</span>
<span class="sd">        fc (torch.nn.Linear): Fully connected layer for output.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nn_units</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the LSTMModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            nn_units (tuple): Number of units in each LSTM layer.</span>
<span class="sd">            dropout (float): Dropout rate for the LSTM layers.</span>
<span class="sd">            input_size (int): Size of the input vocabulary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">nn_units</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">hidden_size</span><span class="o">=</span><span class="n">nn_units</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">nn_units</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># dropout for all but the last layer</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nn_units</span><span class="p">))</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nn_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">input_size</span><span class="p">)</span>

<div class="viewcode-block" id="LSTMModel.forward">
<a class="viewcode-back" href="../../api.html#djalgo.djai.LSTMModel.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Defines the forward pass of the LSTMModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Output tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="GRUModel">
<a class="viewcode-back" href="../../api.html#djalgo.djai.GRUModel">[docs]</a>
<span class="k">class</span> <span class="nc">GRUModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines a GRU model for sequence generation.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        layers (torch.nn.ModuleList): List of GRU layers.</span>
<span class="sd">        fc (torch.nn.Linear): Fully connected layer for output.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nn_units</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the GRUModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            nn_units (tuple): Number of units in each GRU layer.</span>
<span class="sd">            dropout (float): Dropout rate for the GRU layers.</span>
<span class="sd">            input_size (int): Size of the input vocabulary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">nn_units</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                   <span class="n">hidden_size</span><span class="o">=</span><span class="n">nn_units</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                   <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">nn_units</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># dropout for all but the last layer</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nn_units</span><span class="p">))</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nn_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">input_size</span><span class="p">)</span>

<div class="viewcode-block" id="GRUModel.forward">
<a class="viewcode-back" href="../../api.html#djalgo.djai.GRUModel.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Defines the forward pass of the GRUModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Output tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="TransformerModel">
<a class="viewcode-back" href="../../api.html#djalgo.djai.TransformerModel">[docs]</a>
<span class="k">class</span> <span class="nc">TransformerModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines a Transformer model for sequence generation.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        embedding (torch.nn.Linear): Embedding layer to project input size to embedding dimension.</span>
<span class="sd">        encoder_layers (torch.nn.TransformerEncoderLayer): Transformer encoder layer.</span>
<span class="sd">        transformer_encoder (torch.nn.TransformerEncoder): Transformer encoder.</span>
<span class="sd">        fc (torch.nn.Linear): Fully connected layer for output.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nn_units</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the TransformerModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            nn_units (tuple): Number of units in each transformer layer.</span>
<span class="sd">            dropout (float): Dropout rate for the transformer layers.</span>
<span class="sd">            n_heads (int): Number of attention heads.</span>
<span class="sd">            input_size (int): Size of the input vocabulary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">nn_units</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Project input_size to the embedding dimension</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>  <span class="c1"># Xavier initialization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">nn_units</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nhead</span><span class="o">=</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">norm_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_layers</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">nn_units</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nn_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">input_size</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>  <span class="c1"># Xavier initialization</span>

<div class="viewcode-block" id="TransformerModel.forward">
<a class="viewcode-back" href="../../api.html#djalgo.djai.TransformerModel.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Defines the forward pass of the TransformerModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor.</span>
<span class="sd">            attention_mask (torch.Tensor, optional): Attention mask for the transformer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Output tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Project input to the embedding dimension</span>
        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>
</div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/logo.png" alt="Logo"/>
            </a></p>
<h3><a href="../../index.html">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../01_getting-started.html">1. Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../02_harmony.html">2. Harmonies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../03_loops.html">3. Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../04_minimalism.html">4. Minimalism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../05_walks.html">5. Walks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../06_fractals.html">6. Fractals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../07_genetic.html">7. Genetic algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../08_ai.html">8. ðŸ¤– Machine learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">About</a></li>
</ul>

<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><div>
<br/>
<a href="https://www.buymeacoffee.com/essicolo">â˜• Buy me a coffee</a>
</div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Essi Parent.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    

    
  </body>
</html>