<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>8. ğŸ¤– Machine learning &#8212; Djalgo 0.1-alpha documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=12dfc556" />
    <link rel="stylesheet" type="text/css" href="_static/nbsphinx-code-cells.css?v=2aa19091" />
    <script src="_static/documentation_options.js?v=737112c1"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API" href="api.html" />
    <link rel="prev" title="7. Genetic algorithms" href="07_genetic.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="8.-ğŸ¤–-Machine-learning">
<h1>8. ğŸ¤– Machine learning<a class="headerlink" href="#8.-ğŸ¤–-Machine-learning" title="Link to this heading">Â¶</a></h1>
<blockquote>
<div><p><strong>Note</strong>. Djalgoâ€™s AI approach produces uniform outcomes. Want to help? github.com/essicolo/djalgo</p>
</div></blockquote>
<p>We introduced machine learning while fitting Gaussian processes in section <a class="reference external" href="05_walks.html">5. Walks</a>. Djalgoâ€™s module <code class="docutils literal notranslate"><span class="pre">djai</span></code> includes tools for modeling music from MIDI data relying on Tensorflow (a package for deep learning). <code class="docutils literal notranslate"><span class="pre">djai</span></code> is not loaded by default when importing Djalgo, since otherwise Tensorflow, a large and complicated package, should have been added to Djalgoâ€™s dependencies. To use <code class="docutils literal notranslate"><span class="pre">djai</span></code>, you must <a class="reference external" href="https://www.tensorflow.org/install">install Tensorflow</a> in your
environment. <code class="docutils literal notranslate"><span class="pre">djai</span></code> also rely on Music21 to load and process MIDI files: you should also install it with <code class="docutils literal notranslate"><span class="pre">!pip</span> <span class="pre">install</span> <span class="pre">music21</span></code>. Although Music21 is not as fast as Pretty-midi to process MIDI files, I had a better experience with processing files with it. <code class="docutils literal notranslate"><span class="pre">djai</span></code> should be loaded as:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">djalgo</span> <span class="k">as</span> <span class="nn">dj</span>
<span class="kn">from</span> <span class="nn">djalgo</span> <span class="kn">import</span> <span class="n">djai</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2024-04-24 11:52:38.056833: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">djai</span></code> module is designed for processing MIDI files using deep learning models. It extracts pitch, durations, an offset computed in terms of difference in quarter lengths from the previous note (called tick delta) and the (one-hot encoded) track the note belongs to.</p>
<section id="ğŸ’­-Ethics:-art-as-the-witnesses-of-experience">
<h2>ğŸ’­ Ethics: art as the witnesses of experience<a class="headerlink" href="#ğŸ’­-Ethics:-art-as-the-witnesses-of-experience" title="Link to this heading">Â¶</a></h2>
<p>Even though <code class="docutils literal notranslate"><span class="pre">djai</span></code> was the module which took me the most time to develop, it is these days, to my opinion, the least interesting. Who needs to DIY their own AI when interesting results can already be generated with a command prompt to an AI? My ethos will fluctuate and evolve, as anything should in the precious, short time we exist. Their is nothing inherently wrong woth AI, but if your piece was generating with a banal command prompt, your creative process is anything but banal and
uninteresting, no matter the result. In times when any artistic piece needed years of work, the result was as, or more important than the process. Now, when anyone can ask a LLM to generate an image of a cat riding a dinausar in space in the style of a mixed of Daly and cyber-punk, well, results are generated within seconds, and the process becomes more relevant. Nonetheless, if, like me, you have spent months to designed your own AI, the <em>process</em> (not the result) behind the musical piece has
an artistic value as good as any composer who has spent those months studying musical theory. Finally, artists are people who spent the precious time they own to think on the narration of the object they created. When the process becomes applying reciepe, it belongs to home sweet home printed carpets sold on Amazon.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">djai</span></code> module doesnâ€™t come with pre-trained models. That would have been too easy, right? I prefer seeing you tweak it and train it with your own compositions rather than just use it on Leonard Cohen song to generate new one. You worth more than this, and the world deserves more than command-prompt artists.</p>
</section>
<section id="ğŸ—ï¸-Features">
<h2>ğŸ—ï¸ Features<a class="headerlink" href="#ğŸ—ï¸-Features" title="Link to this heading">Â¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">djai</span></code> has the following features.</p>
<ol class="arabic simple">
<li><p><strong>MIDI File Scanning</strong>: Scans directories for MIDI files, allowing for selective processing based on user-defined limits.</p></li>
<li><p><strong>Feature Extraction</strong>: Extracts musical features such as pitch, duration, and timing from MIDI files.</p></li>
<li><p><strong>Data Preprocessing</strong>: Handles scaling and one-hot encoding of musical features for neural network processing.</p></li>
<li><p><strong>Model Training and Prediction</strong>: Supports building and training models for music prediction.</p></li>
<li><p><strong>Music Generation</strong>: Generates new music tracks by predicting sequences of musical notes.</p></li>
</ol>
</section>
<section id="ğŸ§©-Components">
<h2>ğŸ§© Components<a class="headerlink" href="#ğŸ§©-Components" title="Link to this heading">Â¶</a></h2>
<p>There are three classes in <code class="docutils literal notranslate"><span class="pre">djai</span></code>. The <code class="docutils literal notranslate"><span class="pre">DataProcessor</span></code> class is used internally tomanages feature extraction and sequence generation from MIDI files and performs preprocessing tasks such as feature scaling and encoding. <code class="docutils literal notranslate"><span class="pre">DataProcessor</span></code> is automatically called in the second class, <code class="docutils literal notranslate"><span class="pre">ModelManager</span></code>, which facilitates the creation, training, and management of neural network models. <code class="docutils literal notranslate"><span class="pre">ModelManager</span></code> supports three kinds of architectures: <em>LSTM</em>, <em>GRU</em> and <em>transformer</em> and provides
functionalities for model training, prediction, and music generation. The third class, <code class="docutils literal notranslate"><span class="pre">PositionalEncoding</span></code>, is a custom Tensorflow layer used internally to build transformer models.</p>
</section>
<section id="ğŸªœ-Example">
<h2>ğŸªœ Example<a class="headerlink" href="#ğŸªœ-Example" title="Link to this heading">Â¶</a></h2>
<p>I downloaded three midi files were selected to showcase DjAI. To scan the files, use the <code class="docutils literal notranslate"><span class="pre">scan_midi_files</span></code> utility.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">midi_files</span> <span class="o">=</span> <span class="n">djai</span><span class="o">.</span><span class="n">scan_midi_files</span><span class="p">(</span><span class="s1">&#39;_midi&#39;</span><span class="p">)</span>
<span class="n">midi_files</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;_midi/tetris.mid&#39;,
 &#39;_midi/pinkpanther.mid&#39;,
 &#39;_midi/adams.mid&#39;,
 &#39;_midi/rocky.mid&#39;,
 &#39;_midi/mario.mid&#39;]
</pre></div></div>
</div>
<p>The model can be created with a class instanciation comprising a list of arguments, which are explained right away.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_manager</span> <span class="o">=</span> <span class="n">djai</span><span class="o">.</span><span class="n">ModelManager</span><span class="p">(</span>
    <span class="n">sequence_length_i</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">sequence_length_o</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">n_instruments</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="s1">&#39;gru&#39;</span><span class="p">,</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<section id="ğŸ›ï¸-Understanding-Model-Configuration-in-djai">
<h3>ğŸ›ï¸ Understanding Model Configuration in <code class="docutils literal notranslate"><span class="pre">djai</span></code><a class="headerlink" href="#ğŸ›ï¸-Understanding-Model-Configuration-in-djai" title="Link to this heading">Â¶</a></h3>
<section id="Key-Parameters-and-Their-Impact-on-Model-Performance">
<h4>Key Parameters and Their Impact on Model Performance<a class="headerlink" href="#Key-Parameters-and-Their-Impact-on-Model-Performance" title="Link to this heading">Â¶</a></h4>
<p>In the <code class="docutils literal notranslate"><span class="pre">djai</span></code> module, several parameters play critical roles in defining how the neural network learns and generates music based on MIDI files. Letâ€™s break down these parameters for better clarity.</p>
<section id="Sequence-Length">
<h5>Sequence Length<a class="headerlink" href="#Sequence-Length" title="Link to this heading">Â¶</a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sequence_length_i</span></code> and <code class="docutils literal notranslate"><span class="pre">sequence_length_o</span></code> determine the number of notes the model uses to make predictions. Specifically, <code class="docutils literal notranslate"><span class="pre">sequence_length_i</span></code> refers to the number of input notes used to predict the next <code class="docutils literal notranslate"><span class="pre">sequence_length_o</span></code> notes. For example, setting <code class="docutils literal notranslate"><span class="pre">sequence_length_i</span></code> to 30 and <code class="docutils literal notranslate"><span class="pre">sequence_length_o</span></code> to 10 means the model uses 30 notes to predict the subsequent 10 notes. Even though the model predicts a sequence, DjAI retains only the first prediction, an approach named <em>teacher
forcing</em>. The autoregressive approach removes the first item of the sequence to predict from, then append the newly predicted one as basis to predict the next.</p></li>
</ul>
</section>
<section id="Number-of-Instruments">
<h5>Number of Instruments<a class="headerlink" href="#Number-of-Instruments" title="Link to this heading">Â¶</a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_instruments</span></code> specifies how many different instruments the model should consider, starting from the first of each MIDI file. This parameter is crucial for models trained on diverse ensembles. Note that training on MIDI files with fewer instruments than specified can lead to inefficiencies and unnecessary computational overhead.</p></li>
</ul>
</section>
<section id="Model-Type">
<h5>Model Type<a class="headerlink" href="#Model-Type" title="Link to this heading">Â¶</a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_type</span></code> can be set to <code class="docutils literal notranslate"><span class="pre">'lstm'</span></code>, <code class="docutils literal notranslate"><span class="pre">'gru'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'transformer'</span></code>:</p>
<ul>
<li><p>LSTMs (Long Short-Term Memory networks) are more traditional and capable but tend to be complex.</p></li>
<li><p>GRUs (Gated Recurrent Units) aim to simplify the architecture of LSTMs with fewer parameters while maintaining performance.</p></li>
<li><p>Transformers are at the forefront of current large language model (LLM) technology, offering potentially superior learning capabilities due to their attention mechanisms, albeit at the cost of increased complexity and computational demands.</p></li>
</ul>
</li>
</ul>
</section>
<section id="Architecture-Configuration">
<h5>Architecture Configuration<a class="headerlink" href="#Architecture-Configuration" title="Link to this heading">Â¶</a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_layers</span></code> and <code class="docutils literal notranslate"><span class="pre">n_units</span></code> control the depth and width of the neural network. <code class="docutils literal notranslate"><span class="pre">n_layers</span></code> is the number of layers in the network, and <code class="docutils literal notranslate"><span class="pre">n_units</span></code> represents the number of neurons in each of these layers. <code class="docutils literal notranslate"><span class="pre">n_heads</span></code> is the number of heads in the multi-head attention algorithm, and is only taken into account in the <em>transformer</em> model type.</p></li>
</ul>
</section>
<section id="Training-Dynamics">
<h5>Training Dynamics<a class="headerlink" href="#Training-Dynamics" title="Link to this heading">Â¶</a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dropout</span></code> is a technique to prevent overfitting by randomly deactivating a portion of the neurons during training, specified by a ratio between 0 and 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> affects how many samples are processed before the model updates its internal parameters, impacting both training speed and convergence behavior.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> influences the step size at each iteration in the training process. A higher learning rate can cause overshooting optimal solutions, while a very low rate may lead to slow convergence.</p></li>
</ul>
</section>
<section id="Loss-Weights">
<h5>Loss Weights<a class="headerlink" href="#Loss-Weights" title="Link to this heading">Â¶</a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">loss_weights</span></code> allows customization of the importance of different prediction components such as pitch, duration, offset, and time delta, potentially skewing the model to prioritize accuracy in specific areas.</p></li>
</ul>
</section>
</section>
</section>
<section id="ğŸ‹ï¸-Fitting-the-Model">
<h3>ğŸ‹ï¸ Fitting the Model<a class="headerlink" href="#ğŸ‹ï¸-Fitting-the-Model" title="Link to this heading">Â¶</a></h3>
<p>To train the model, you use the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> method with a list of MIDI file paths. The number of epochs, which represent complete passes over the entire dataset, can be adjusted according to the complexity of the task and desired accuracy. More epochs typically lead to better model performance but require more time to complete.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model_manager</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">midi_files</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">8s</span> 71ms/step - loss: 0.1528
Epoch 2/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">1s</span> 70ms/step - loss: 0.0665
Epoch 3/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">2s</span> 73ms/step - loss: 0.0585
Epoch 4/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">2s</span> 73ms/step - loss: 0.0552
Epoch 5/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">1s</span> 71ms/step - loss: 0.0537
Epoch 6/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">2s</span> 71ms/step - loss: 0.0516
Epoch 7/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">2s</span> 71ms/step - loss: 0.0523
Epoch 8/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">2s</span> 80ms/step - loss: 0.0508
Epoch 9/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">2s</span> 77ms/step - loss: 0.0503
Epoch 10/10
<span class="ansi-bold">21/21</span> <span class="ansi-green-fg">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span class="ansi-bold">2s</span> 85ms/step - loss: 0.0506
</pre></div></div>
</div>
<p>Models are long to fit, so you might want to save it for future use.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_manager</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;_output/lstm.keras&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>To predict a new sequence, you can use the <code class="docutils literal notranslate"><span class="pre">.generate()</span></code> method of the <code class="docutils literal notranslate"><span class="pre">djai.ModelManager</span></code> object. The generate method takes the first notes of a MIDI file (defined in <code class="docutils literal notranslate"><span class="pre">sequence_length_i</span></code>) and returns a Djalgo track or, for multiple instruments, a list of tracks. Make sure that the MIDI file has enough notes.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model_manager</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39;_output/polyloop.mid&#39;</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">predictions</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[(68, 0.9924258, 0.28069848),
 (68, 0.99277496, 0.28115964),
 (68, 0.9936436, 0.28131378),
 (69, 0.99493337, 0.28136227),
 (69, 0.9964782, 0.28146863),
 (69, 0.9980702, 0.28165814),
 (69, 0.9995358, 0.28189823),
 (69, 1.0007924, 0.28215533),
 (69, 1.0018008, 0.28239486),
 (69, 1.0025604, 0.28259254)]
</pre></div></div>
</div>
<p>Predictions are uniform and clearly not suited yet for music yet.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/logo.png" alt="Logo"/>
            </a></p>
<h3><a href="index.html">Table of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="01_getting-started.html">1. Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_harmony.html">2. Harmonies</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_loops.html">3. Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_minimalism.html">4. Minimalism</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_walks.html">5. Walks</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_fractals.html">6. Fractals</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_genetic.html">7. Genetic algorithms</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">8. ğŸ¤– Machine learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html">About</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script><div>
<br/>
<a href="https://www.buymeacoffee.com/essicolo">â˜• Buy me a coffee</a>
</div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Essi Parent.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/08_ai.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>