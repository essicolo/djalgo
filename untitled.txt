Traceback (most recent call last):
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/jupyter_ai/chat_handlers/base.py", line 113, in on_message
    await self.process_message(message)
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/jupyter_ai/chat_handlers/default.py", line 57, in process_message
    response = await self.llm_chain.apredict(input=message.body, stop=["\nHuman:"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain/chains/llm.py", line 310, in apredict
    return (await self.acall(kwargs, callbacks=callbacks))[self.output_key]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain_core/_api/deprecation.py", line 154, in awarning_emitting_wrapper
    return await wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain/chains/base.py", line 428, in acall
    return await self.ainvoke(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain/chains/base.py", line 212, in ainvoke
    raise e
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain/chains/base.py", line 203, in ainvoke
    await self._acall(inputs, run_manager=run_manager)
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain/chains/llm.py", line 275, in _acall
    response = await self.agenerate([inputs], run_manager=run_manager)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain/chains/llm.py", line 142, in agenerate
    return await self.llm.agenerate_prompt(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 556, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 516, in agenerate
    raise exceptions[0]
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 638, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain_community/chat_models/openai.py", line 534, in _agenerate
    response = await acompletion_with_retry(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/langchain_community/chat_models/openai.py", line 105, in acompletion_with_retry
    return await llm.async_client.create(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 1334, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/openai/_base_client.py", line 1738, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/openai/_base_client.py", line 1441, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/openai/_base_client.py", line 1517, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/openai/_base_client.py", line 1563, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/openai/_base_client.py", line 1517, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/openai/_base_client.py", line 1563, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/essi/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/openai/_base_client.py", line 1532, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
