{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install gpflow tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import music21 as m21\n",
    "import djalgo as dj\n",
    "\n",
    "def scan_midi_files(directory, max_files=None):\n",
    "    \"\"\"\n",
    "    Scans the specified directory for MIDI files using glob with a while loop.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory to scan for MIDI files.\n",
    "        max_files (int, optional): The maximum number of files to scan. If None, all files are scanned.\n",
    "\n",
    "    Returns:\n",
    "        list: The list of MIDI files found.\n",
    "    \"\"\"\n",
    "    search_pattern = os.path.join(directory, '**', '*.mid*')\n",
    "    midi_files = []\n",
    "\n",
    "    # Utiliser glob.iglob pour obtenir un itÃ©rateur\n",
    "    for file in glob.iglob(search_pattern, recursive=True):\n",
    "        midi_files.append(file)\n",
    "        if max_files is not None and len(midi_files) >= max_files:\n",
    "            break\n",
    "\n",
    "    return midi_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_files = scan_midi_files('_midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "from mido import MidiFile, MidiTrack\n",
    "\n",
    "def repair_midi(input_path, output_path, split_channels=False, change_instruments=None):\n",
    "    \"\"\"\n",
    "    Repairs a MIDI file by splitting or merging tracks and optionally changing instruments.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the input MIDI file.\n",
    "        output_path (str): Path to save the repaired MIDI file.\n",
    "        split_channels (bool): If True, splits tracks into separate tracks based on channel.\n",
    "        change_instruments (dict): Optional dictionary mapping from channel to new instrument program number.\n",
    "    \"\"\"\n",
    "    mid = MidiFile(input_path)\n",
    "    new_mid = MidiFile()\n",
    "    \n",
    "    if split_channels:\n",
    "        # Create a track for each channel (0-15)\n",
    "        tracks_per_channel = [MidiTrack() for _ in range(16)]\n",
    "        \n",
    "        # Distribute messages to appropriate track based on channel\n",
    "        for track in mid.tracks:\n",
    "            for msg in track:\n",
    "                if not msg.is_meta and hasattr(msg, 'channel'):\n",
    "                    if change_instruments and msg.type == 'program_change' and msg.channel in change_instruments:\n",
    "                        msg.program = change_instruments[msg.channel]\n",
    "                    tracks_per_channel[msg.channel].append(msg)\n",
    "                else:\n",
    "                    # Append meta messages to all tracks\n",
    "                    [t.append(msg) for t in tracks_per_channel]\n",
    "                    \n",
    "        # Add non-empty tracks to the new MIDI file\n",
    "        for track in tracks_per_channel:\n",
    "            if any(not msg.is_meta for msg in track):  # Ensuring the track is not empty\n",
    "                new_mid.tracks.append(track)\n",
    "    else:\n",
    "        # Merge all tracks into one or keep as is, based on the MIDI file's structure\n",
    "        combined_track = MidiTrack()\n",
    "        for track in mid.tracks:\n",
    "            for msg in track:\n",
    "                if change_instruments and msg.type == 'program_change' and msg.channel in change_instruments:\n",
    "                    msg.program = change_instruments[msg.channel]\n",
    "                combined_track.append(msg)\n",
    "        new_mid.tracks.append(combined_track)\n",
    "        \n",
    "    # Save the repaired MIDI file\n",
    "    new_mid.save(output_path)\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "for file in midi_files:\n",
    "    repair_midi(file, file.replace('_midi/', '_midi-repaired/'), split_channels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_files = scan_midi_files('_midi-repaired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_midi-repaired/adams.mid',\n",
       " '_midi-repaired/mario.mid',\n",
       " '_midi-repaired/pinkpanther.mid',\n",
       " '_midi-repaired/rocky.mid',\n",
       " '_midi-repaired/tetris.mid']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: _midi-repaired/adams.mid, length: 2 parts\n",
      "File: _midi-repaired/mario.mid, length: 2 parts\n",
      "File: _midi-repaired/pinkpanther.mid, length: 2 parts\n",
      "File: _midi-repaired/rocky.mid, length: 2 parts\n",
      "File: _midi-repaired/tetris.mid, length: 2 parts\n"
     ]
    }
   ],
   "source": [
    "for midi_file in midi_files:\n",
    "    score = m21.converter.parse(midi_file)\n",
    "    parts = score.getElementsByClass(m21.stream.Part)\n",
    "    print(f'File: {midi_file}, length: {len(parts)} parts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import music21 as m21\n",
    "\n",
    "def replace_none_with_weighted_value(data):\n",
    "    # Copy data to avoid modifying the original array directly\n",
    "    modified_data = np.array(data, dtype=object)\n",
    "    for i in range(len(modified_data)):\n",
    "        if modified_data[i] is None:\n",
    "            nearest_prev = nearest_next = None\n",
    "            dist_prev = dist_next = float('inf')\n",
    "            \n",
    "            for j in range(i - 1, -1, -1):\n",
    "                if modified_data[j] is not None:\n",
    "                    nearest_prev = modified_data[j]\n",
    "                    dist_prev = i - j\n",
    "                    break\n",
    "            \n",
    "            for k in range(i + 1, len(modified_data)):\n",
    "                if modified_data[k] is not None:\n",
    "                    nearest_next = modified_data[k]\n",
    "                    dist_next = k - i\n",
    "                    break\n",
    "            \n",
    "            if nearest_prev is not None and nearest_next is not None:\n",
    "                total_weight = 1 / dist_prev + 1 / dist_next\n",
    "                weighted_value = (nearest_prev * (1 / dist_prev) + nearest_next * (1 / dist_next)) / total_weight\n",
    "            elif nearest_prev is not None:\n",
    "                weighted_value = nearest_prev\n",
    "            elif nearest_next is not None:\n",
    "                weighted_value = nearest_next\n",
    "            else:\n",
    "                weighted_value = 0  # Default or handle as needed\n",
    "\n",
    "            modified_data[i] = weighted_value\n",
    "    return modified_data\n",
    "\n",
    "\n",
    "def prepare_data_for_gpflow(midi_files, num_instruments=2):\n",
    "    features = []  # Will hold the input features\n",
    "    targets = []   # Will hold the targets with instrument index\n",
    "\n",
    "    for midi_file in midi_files:\n",
    "        score = m21.converter.parse(midi_file)\n",
    "        parts = score.getElementsByClass(m21.stream.Part)\n",
    "        for idx, part in enumerate(parts[:num_instruments]):\n",
    "            key = part.analyze('key')\n",
    "            scale_list = dj.harmony.Scale(key.tonic.name, key.mode).generate()            \n",
    "            for element in part.flatten().notesAndRests:\n",
    "                offset = float(element.offset)\n",
    "                duration = float(element.duration.quarterLength)\n",
    "                activity = 0 if isinstance(element, m21.note.Rest) else 1\n",
    "                \n",
    "                if isinstance(element, m21.note.Note):\n",
    "                    pitch = element.pitch.midi\n",
    "                elif isinstance(element, m21.chord.Chord):\n",
    "                    pitch = element.pitches[0].midi\n",
    "                else:\n",
    "                    pitch = None\n",
    "                \n",
    "                degree = dj.utils.get_degree_from_pitch(pitch, scale_list=scale_list, tonic_pitch=key.tonic.midi) if pitch is not None else None\n",
    "                \n",
    "                features.append([offset, idx])  # Features (time offset)\n",
    "                # Concatenating instrument index with each target\n",
    "                targets.append([degree, duration, activity])\n",
    "\n",
    "    # Replace None values in degrees with a weighted average of the nearest non-None values\n",
    "    all_degrees = [t[0] for t in targets]\n",
    "    all_degrees_noNone = replace_none_with_weighted_value(all_degrees)\n",
    "    targets = [[all_degrees_noNone[i], t[1], t[2]] for i, t in enumerate(targets)]\n",
    "        \n",
    "    X = np.array(features).astype(np.float64)\n",
    "    Y = np.array(targets).astype(np.float64)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "# Example usage\n",
    "num_instruments=2\n",
    "midi_files = scan_midi_files('_midi-repaired')\n",
    "X, Y = prepare_data_for_gpflow(midi_files, num_instruments=num_instruments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(x):\n",
    "    mean = np.mean(x, axis=0)\n",
    "    std = np.std(x, axis=0)\n",
    "    return (x - mean) / std, mean, std\n",
    "\n",
    "\n",
    "Y_sc = Y.copy()\n",
    "Y_sc[:, :2], mean, std = scaling(Y[:, :2])\n",
    "\n",
    "X_sc = X.copy()\n",
    "X_sc[:, 0], mean_X, std_X = scaling(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28407026,  0.        ],\n",
       "       [-1.26243537,  0.        ],\n",
       "       [-1.24080048,  0.        ],\n",
       "       ...,\n",
       "       [-0.72156317,  1.        ],\n",
       "       [-0.71615445,  1.        ],\n",
       "       [-0.71074573,  1.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39304276,  2.28918835,  0.        ],\n",
       "       [-0.39304276,  2.28918835,  0.        ],\n",
       "       [-0.39304276,  0.70454098,  0.        ],\n",
       "       ...,\n",
       "       [-0.4499179 , -0.0877827 ,  1.        ],\n",
       "       [-0.27929249, -0.0877827 ,  1.        ],\n",
       "       [-0.27929249,  0.70454098,  0.        ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from gpflow.utilities import print_summary\n",
    "from gpflow.kernels import MultioutputKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "\n",
    "\n",
    "# Define the base kernel for the GPs\n",
    "base_kernel = gpflow.kernels.SquaredExponential()\n",
    "\n",
    "# Number of outputs matches the number of instruments\n",
    "num_outputs = int(np.max(X_sc[:, 1]) + 1)  # Assuming column 1 is the index of instruments\n",
    "\n",
    "# Coregionalization kernel setup\n",
    "coreg_kernel = gpflow.kernels.Coregion(output_dim=num_outputs, rank=num_outputs, active_dims=[1])\n",
    "coreg_kernel.W.assign(np.random.rand(num_outputs, num_outputs))\n",
    "\n",
    "# Combine the base kernel with the coregionalization kernel\n",
    "# Ensure each model type (degrees, durations, activities) has its own combined kernel\n",
    "kernel_degrees = base_kernel * coreg_kernel\n",
    "kernel_durations = base_kernel * coreg_kernel\n",
    "kernel_activities = base_kernel * coreg_kernel\n",
    "\n",
    "# Setup the GP models for each output\n",
    "# Use X_sc which contains the scaled features including time and instrument index\n",
    "model_degrees = gpflow.models.SVGP(kernel=kernel_degrees, likelihood=gpflow.likelihoods.Gaussian(), inducing_variable=X_sc.copy())\n",
    "model_durations = gpflow.models.SVGP(kernel=kernel_durations, likelihood=gpflow.likelihoods.Gaussian(), inducing_variable=X_sc.copy())\n",
    "model_activities = gpflow.models.SVGP(kernel=kernel_activities, likelihood=gpflow.likelihoods.Bernoulli(), inducing_variable=X_sc.copy())\n",
    "\n",
    "# Define training data for each model using the appropriate columns from Y\n",
    "training_data_degrees = (X_sc, Y_sc[:, 0:1])  # First column of Y for degrees\n",
    "training_data_durations = (X_sc, Y_sc[:, 1:2])  # Second column of Y for durations\n",
    "training_data_activities = (X_sc, Y_sc[:, 2:3])  # Third column of Y for activities\n",
    "\n",
    "# Optimization using GPflow's built-in optimizer for each model\n",
    "optimizer = gpflow.optimizers.Scipy()\n",
    "optimizer.minimize(model_degrees.training_loss_closure(training_data_degrees),\n",
    "                   variables=model_degrees.trainable_variables,\n",
    "                   options=dict(maxiter=100))\n",
    "optimizer.minimize(model_durations.training_loss_closure(training_data_durations),\n",
    "                   variables=model_durations.trainable_variables,\n",
    "                   options=dict(maxiter=100))\n",
    "optimizer.minimize(model_activities.training_loss_closure(training_data_activities),\n",
    "                   variables=model_activities.trainable_variables,\n",
    "                   options=dict(maxiter=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicbook",
   "language": "python",
   "name": "musicbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
